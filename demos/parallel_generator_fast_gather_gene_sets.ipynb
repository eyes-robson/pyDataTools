{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import itertools as it\n",
    "import functools as ft\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sklearn\n",
    "import sklearn.preprocessing as pre\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isrobson/.local/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "dat = pd.read_csv('./cord_blood_kinases.csv', sep=',', header=0, index_col=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_sets(row, oe_csr):\n",
    "    return oe_csr[row['lower']:row['upper']].sum(axis=0)\n",
    "\n",
    "def first_candidates(cells, cell_sets, min_shared_cells):\n",
    "    count_filter = cell_sets.apply(len) > min_shared_cells\n",
    "    return list(map(lambda x: frozenset([x]), ((cells[count_filter])))), {frozenset([x]):y for x,y in cell_sets[count_filter].to_dict().items()}\n",
    "\n",
    "def intersector(tuple_of_candidates, tuple_of_sets):\n",
    "    return ft.reduce(lambda x,y: x.union(y), tuple_of_candidates), tuple_of_sets[0] & tuple_of_sets[1]\n",
    "\n",
    "def cell_set_getter(input_list, cell_sets):\n",
    "    for i in input_list:\n",
    "        yield cell_sets[i]\n",
    "        \n",
    "def make_gener(left, right, min_shared_cells, cell_sets, q):\n",
    "    left_gen = cell_set_getter(left, cell_sets)\n",
    "    right_gen = cell_set_getter(right, cell_sets)        \n",
    "    gener = ((x, y) for x, y in map(intersector, *(zip(left, right),zip(left_gen, right_gen))) if len(y)>min_shared_cells)\n",
    "    q.put(dict(list(gener)))\n",
    "    return \n",
    "\n",
    "def parallel_combo_generator(chunk, full_list, k, q):\n",
    "    local_list = list(filter(lambda x: len(x[0]|x[1]) == k, it.product(chunk, full_list)))\n",
    "    if(len(local_list) == 0):\n",
    "        q.put(None)\n",
    "    else:\n",
    "        left, right = zip(*local_list)\n",
    "        q.put((len(local_list),iter(left), iter(right)))\n",
    "    return\n",
    "        \n",
    "def pickle_cells(cell_sets, k):\n",
    "    '''These files are gonna be decently big. Do not want to keep them in memory.'''\n",
    "    with open('cell_sets_' + str(k) + '.pickle', 'wb') as f:\n",
    "        pickle.dump(cell_sets, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def zip_helper(gener_slice, q):\n",
    "    q.put(list(gener_slice))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_gather_gene_sets(dat, min_shared_cells = 100, min_percent_cells = None, max_cluster_size = sys.maxsize):\n",
    "    st = time.time()\n",
    "    begin = st\n",
    "    cores = max(mp.cpu_count()-1, 1)\n",
    "    \n",
    "    total_cells = dat['barcode'].nunique()\n",
    "    \n",
    "    if(min_percent_cells is not None):\n",
    "        min_shared_cells = int(min_percent_cells * total_cells)\n",
    "\n",
    "    cell_id_dict = {y:x for x,y in enumerate(dat['symbol'].unique())}\n",
    "    dat['symbol'] = dat['symbol'].map(cell_id_dict)\n",
    "    cells = dat['symbol'].unique()\n",
    "    \n",
    "    barcode_id_dict = {y:x for x,y in enumerate(dat['barcode'].unique())}\n",
    "    dat['barcode'] = dat['barcode'].map(barcode_id_dict)\n",
    "    \n",
    "    cell_sets = dat.groupby('symbol')['barcode'].apply(set)\n",
    "    \n",
    "    en = time.time()\n",
    "    \n",
    "    print('Formatted data in ' + str(en-st) + ' seconds')\n",
    "    \n",
    "    cells, cell_sets = first_candidates(cells, cell_sets, min_shared_cells)\n",
    "    \n",
    "    print(str(len(cells)) + ' genes made have > ' + str(min_shared_cells) + ' cells')\n",
    "    \n",
    "    k = 2\n",
    "    n = len(cells)\n",
    "    \n",
    "    pickle_cells(cell_sets, k)\n",
    "    \n",
    "    while(len(cells) > 0 and k < max_cluster_size):\n",
    "        st = time.time()\n",
    "        \n",
    "        q = mp.JoinableQueue()\n",
    "        \n",
    "        candidates_output = []\n",
    "        candidate_iter = iter(cell_sets.keys())\n",
    "        kwarg_dict={'k':k,'full_list':cell_sets.keys(),'q':q}\n",
    "        \n",
    "        for i in range(cores-1):\n",
    "            p = mp.Process(target=parallel_combo_generator, args=(it.islice(candidate_iter, n//cores),), kwargs=kwarg_dict)\n",
    "            p.start()\n",
    "\n",
    "        for i in range(1):\n",
    "            p = mp.Process(target=parallel_combo_generator, args=(it.islice(candidate_iter, n//cores),), kwargs=kwarg_dict)\n",
    "            p.start()\n",
    "            \n",
    "        for i in range(cores):\n",
    "            t = q.get()\n",
    "            candidates_output += [t] if t is not None else []\n",
    "            q.task_done()\n",
    "            \n",
    "        while(not q.empty()):\n",
    "            q.get()\n",
    "            q.task_done()\n",
    "            \n",
    "        q.join()\n",
    "        q.close()\n",
    "        \n",
    "        if(len(candidates_output) == 0):\n",
    "            print('No new candidates!')\n",
    "            print('Terminated! Total run time: ' + str(en - begin) + ' seconds')\n",
    "            break\n",
    "            \n",
    "        lengths, candidates_left, candidates_right = zip(*candidates_output)\n",
    "        candidates_left = it.chain.from_iterable(candidates_left)\n",
    "        candidates_right = it.chain.from_iterable(candidates_right)\n",
    "        cand_len = sum(lengths) \n",
    "        \n",
    "        q = mp.JoinableQueue()\n",
    "        \n",
    "        kwarg_dict={'min_shared_cells':min_shared_cells,'cell_sets':cell_sets,'q':q}\n",
    "\n",
    "        for i in range(cores-1):\n",
    "            p = mp.Process(target=make_gener, args=(list(it.islice(candidates_left, cand_len//cores)), list(it.islice(candidates_right, cand_len//cores))), kwargs=kwarg_dict)\n",
    "            p.start()\n",
    "\n",
    "        for i in range(1):\n",
    "            p = mp.Process(target=make_gener, args=(list(candidates_left), list(candidates_right)), kwargs=kwarg_dict)\n",
    "            p.start()\n",
    "\n",
    "        en = time.time()\n",
    "        print('Finished launching processes in: '+ str(time.time()-st) + ' seconds')\n",
    "            \n",
    "        output = []\n",
    "        for i in range(cores):\n",
    "            t = q.get()\n",
    "            output += [t] if t is not None else []\n",
    "            q.task_done()\n",
    "            \n",
    "        print('Finished merging cells in: ' + str(time.time() - en) + ' seconds')\n",
    "            \n",
    "        if(len(output) == 0):\n",
    "            print('No results from parallel output!')\n",
    "            print('Terminated! Total run time: ' + str(en - begin) + ' seconds')\n",
    "            break\n",
    "            \n",
    "\n",
    "        cell_sets = ft.reduce(lambda x,y: {**x, **y}, output)\n",
    "        \n",
    "        k+= 1\n",
    "        n = len(cell_sets)\n",
    "        \n",
    "        en = time.time()\n",
    "        \n",
    "        print('Found ' + str(n) + ' remaining gene clusters with > ' + str(min_shared_cells) + ' of size: ' +str(k-1))\n",
    "        print('Iteration took: ' + str(en-st) + ' seconds')\n",
    "        print('Total time: ' + str(en - begin) + ' seconds')\n",
    "        \n",
    "        if(n == 0):\n",
    "            print('Terminated! Total run time: ' + str(en - begin) + ' seconds')\n",
    "            break\n",
    "        else:\n",
    "            print('Pickling!')\n",
    "            pickle_cells(cell_sets, k-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted data in 3.1762821674346924 seconds\n",
      "194 genes made have > 8215 cells\n",
      "Finished launching processes in: 0.4543280601501465 seconds\n",
      "Finished merging cells in: 21.244075059890747 seconds\n",
      "Found 902 remaining gene clusters with > 8215 of size: 2\n",
      "Iteration took: 21.698889017105103 seconds\n",
      "Total time: 25.101996183395386 seconds\n",
      "Pickling!\n",
      "Finished launching processes in: 3.7371368408203125 seconds\n",
      "Finished merging cells in: 26.8359591960907 seconds\n",
      "Found 332 remaining gene clusters with > 8215 of size: 3\n",
      "Iteration took: 30.574381113052368 seconds\n",
      "Total time: 56.22268223762512 seconds\n",
      "Pickling!\n",
      "Finished launching processes in: 1.8558001518249512 seconds\n",
      "Finished merging cells in: 3.5507590770721436 seconds\n",
      "Found 69 remaining gene clusters with > 8215 of size: 4\n",
      "Iteration took: 5.407005310058594 seconds\n",
      "Total time: 61.8050754070282 seconds\n",
      "Pickling!\n",
      "Finished launching processes in: 0.17078614234924316 seconds\n",
      "Finished merging cells in: 0.28032898902893066 seconds\n",
      "Found 1 remaining gene clusters with > 8215 of size: 5\n",
      "Iteration took: 0.4513421058654785 seconds\n",
      "Total time: 62.301629304885864 seconds\n",
      "Pickling!\n",
      "No new candidates!\n",
      "Terminated! Total run time: 62.301629304885864 seconds\n"
     ]
    }
   ],
   "source": [
    "fast_gather_gene_sets(dat, min_percent_cells = 0.03)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
