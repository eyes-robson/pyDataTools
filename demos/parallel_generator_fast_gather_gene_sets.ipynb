{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import itertools as it\n",
    "import functools as ft\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sklearn\n",
    "import sklearn.preprocessing as pre\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat = pd.read_csv('./cord_blood_kinases.csv', sep=',', header=0, index_col=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_sets(row, oe_csr):\n",
    "    return oe_csr[row['lower']:row['upper']].sum(axis=0)\n",
    "\n",
    "def first_candidates(cells, cell_sets, min_shared_cells):\n",
    "    count_filter = cell_sets.apply(len) > min_shared_cells\n",
    "    return list(map(lambda x: frozenset([x]), ((cells[count_filter])))), {frozenset([x]):y for x,y in cell_sets[count_filter].to_dict().items()}\n",
    "\n",
    "def intersector(tuple_of_candidates, tuple_of_sets):\n",
    "    return ft.reduce(lambda x,y: x.union(y), tuple_of_candidates), tuple_of_sets[0] & tuple_of_sets[1]\n",
    "\n",
    "def cell_set_getter(input_list, cell_sets):\n",
    "    for i in input_list:\n",
    "        yield cell_sets[i]\n",
    "        \n",
    "def make_gener(left, right, min_shared_cells, cell_sets, q):\n",
    "    left_gen = cell_set_getter(left, cell_sets)\n",
    "    right_gen = cell_set_getter(right, cell_sets)        \n",
    "    gener = ((x, y) for x, y in map(intersector, *(zip(left, right),zip(left_gen, right_gen))) if len(y)>min_shared_cells)\n",
    "    q.put(zip(*gener))\n",
    "    return \n",
    "        \n",
    "def pickle_cells(cells, cell_sets, k):\n",
    "    '''These files are gonna be decently big. Do not want to keep them in memory.'''\n",
    "    with open('cell_' + str(k) + '.pickle', 'wb') as f:\n",
    "        pickle.dump(cells, f, pickle.HIGHEST_PROTOCOL)\n",
    "    with open('cell_sets_' + str(k) + '.pickle', 'wb') as f:\n",
    "        pickle.dump(cell_sets, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_helper(gener_slice, q):\n",
    "    q.put(list(gener_slice))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_gather_gene_sets(dat, min_shared_cells = 100, min_percent_cells = None, max_cluster_size = sys.maxsize):\n",
    "    st = time.time()\n",
    "    begin = st\n",
    "    cores = max(mp.cpu_count()-1, 1)\n",
    "    \n",
    "    total_cells = dat['barcode'].nunique()\n",
    "    \n",
    "    if(min_percent_cells is not None):\n",
    "        min_shared_cells = int(min_percent_cells * total_cells)\n",
    "\n",
    "    cell_id_dict = {y:x for x,y in enumerate(dat['symbol'].unique())}\n",
    "    dat['symbol'] = dat['symbol'].map(cell_id_dict)\n",
    "    cells = dat['symbol'].unique()\n",
    "    \n",
    "    barcode_id_dict = {y:x for x,y in enumerate(dat['barcode'].unique())}\n",
    "    dat['barcode'] = dat['barcode'].map(barcode_id_dict)\n",
    "    \n",
    "    cell_sets = dat.groupby('symbol')['barcode'].apply(set)\n",
    "    \n",
    "    en = time.time()\n",
    "    \n",
    "    print('Formatted data in ' + str(en-st) + ' seconds')\n",
    "    \n",
    "    cells, cell_sets = first_candidates(cells, cell_sets, min_shared_cells)\n",
    "    \n",
    "    print(str(len(cells)) + ' genes made have > ' + str(min_shared_cells) + ' cells')\n",
    "    \n",
    "    k = 2\n",
    "    n = len(cells)\n",
    "    \n",
    "    pickle_cells(cells, cell_sets, k)\n",
    "    \n",
    "    while(len(cells) > 0 and k < max_cluster_size):\n",
    "        st = time.time()\n",
    "    \n",
    "        candidates_left, candidates_right = zip(*list(filter(lambda x: len(x[0]|x[1]) == k, it.combinations(cells, 2))))\n",
    "        \n",
    "        cand_len = len(candidates_left)\n",
    "        candidates_left = iter(candidates_left)\n",
    "        candidates_right = iter(candidates_right)\n",
    "\n",
    "        q = mp.JoinableQueue()\n",
    "        kwarg_dict={'min_shared_cells':min_shared_cells,'cell_sets':cell_sets,'q':q}\n",
    "\n",
    "        for i in range(cores-1):\n",
    "            p = mp.Process(target=make_gener, args=(list(it.islice(candidates_left, cand_len//cores)), list(it.islice(candidates_right, cand_len//cores))), kwargs=kwarg_dict)\n",
    "            p.start()\n",
    "\n",
    "        for i in range(1):\n",
    "            p = mp.Process(target=make_gener, args=(list(candidates_left), list(candidates_right)), kwargs=kwarg_dict)\n",
    "            p.start()\n",
    "\n",
    "        print('Finished launching processes in: '+ str(time.time()-st) + ' seconds')\n",
    "            \n",
    "        output = []\n",
    "        for i in range(cores):\n",
    "            output.append(q.get())\n",
    "            q.task_done()\n",
    "\n",
    "        cells, cell_sets = zip(*output)\n",
    "        cells = [item for tup in cells for item in tup]\n",
    "        cell_sets = [item for tup in cell_sets for item in tup]\n",
    "        cell_sets = dict(zip(cells, cell_sets))\n",
    "        \n",
    "        k+= 1\n",
    "        n = len(cells)\n",
    "        \n",
    "        en = time.time()\n",
    "        \n",
    "        print('Found ' + str(n) + ' remaining gene clusters with > ' + str(min_shared_cells) + ' of size: ' +str(k-1))\n",
    "        print('Iteration took: ' + str(en-st) + ' seconds')\n",
    "        print('Total time: ' + str(en - begin) + ' seconds')\n",
    "        \n",
    "        if(n == 0):\n",
    "            print('Terminated! Total run time: ' + str(en - begin) + ' seconds')\n",
    "        else:\n",
    "            print('Pickling!')\n",
    "            pickle_cells(cells, cell_sets, k-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fast_gather_gene_sets(dat, min_percent_cells = 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
