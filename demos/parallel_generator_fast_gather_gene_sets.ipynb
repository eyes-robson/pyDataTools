{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import itertools as it\n",
    "import functools as ft\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sklearn\n",
    "import sklearn.preprocessing as pre\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat = pd.read_csv('./cord_blood_kinases.csv', sep=',', header=0, index_col=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_sets(row, oe_csr):\n",
    "    return oe_csr[row['lower']:row['upper']].sum(axis=0)\n",
    "\n",
    "def first_candidates(cells, cell_sets, min_shared_cells):\n",
    "    count_filter = cell_sets.apply(len) > min_shared_cells\n",
    "    return list(map(lambda x: frozenset([x]), ((cells[count_filter])))), {frozenset([x]):y for x,y in cell_sets[count_filter].to_dict().items()}\n",
    "\n",
    "def intersector(tuple_of_candidates, tuple_of_sets):\n",
    "    return ft.reduce(lambda x,y: x.union(y), tuple_of_candidates), tuple_of_sets[0] & tuple_of_sets[1]\n",
    "\n",
    "def cell_set_getter(input_list, cell_sets):\n",
    "    for i in input_list:\n",
    "        yield cell_sets[i]\n",
    "        \n",
    "def make_gener(left, right, min_shared_cells, cell_sets, q):\n",
    "    left_gen = cell_set_getter(left, cell_sets)\n",
    "    right_gen = cell_set_getter(right, cell_sets)        \n",
    "    gener = ((x, y) for x, y in map(intersector, *(zip(left, right),zip(left_gen, right_gen))) if len(y)>min_shared_cells)\n",
    "    q.put(dict(list(gener)))\n",
    "    return \n",
    "\n",
    "def take_from(gener, size):\n",
    "    yield it.takewhile(lambda x: len(x) > 0, list(it.islice(gener, size)))\n",
    "\n",
    "def parallel_combo_generator(chunk, full_list, k, q):\n",
    "    local_list = list(filter(lambda x: len(x[0]|x[1]) == k, it.product(chunk, full_list)))\n",
    "    if(len(local_list) == 0):\n",
    "        q.put(None)\n",
    "    else:\n",
    "        left, right = zip(*local_list)\n",
    "        q.put((len(local_list),iter(left), iter(right)))\n",
    "    return\n",
    "        \n",
    "def pickle_cells(cell_sets, k):\n",
    "    '''These files are gonna be decently big. Do not want to keep them in memory.'''\n",
    "    with open('cell_sets_' + str(k) + '.pickle', 'wb') as f:\n",
    "        pickle.dump(cell_sets, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def zip_helper(gener_slice, q):\n",
    "    q.put(list(gener_slice))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_gather_gene_sets(dat, min_shared_cells = 100, min_percent_cells = None, max_cluster_size = sys.maxsize):\n",
    "    st = time.time()\n",
    "    begin = st\n",
    "    cores = max(mp.cpu_count()-1, 1)\n",
    "    \n",
    "    total_cells = dat['barcode'].nunique()\n",
    "    \n",
    "    if(min_percent_cells is not None):\n",
    "        min_shared_cells = min_percent_cells * total_cells\n",
    "\n",
    "    cell_id_dict = {y:x for x,y in enumerate(dat['symbol'].unique())}\n",
    "    dat['symbol'] = dat['symbol'].map(cell_id_dict)\n",
    "    cells = dat['symbol'].unique()\n",
    "    \n",
    "    barcode_id_dict = {y:x for x,y in enumerate(dat['barcode'].unique())}\n",
    "    dat['barcode'] = dat['barcode'].map(barcode_id_dict)\n",
    "    \n",
    "    cell_sets = dat.groupby('symbol')['barcode'].apply(set)\n",
    "    \n",
    "    en = time.time()\n",
    "    \n",
    "    print('Formatted data in ' + str(en-st) + ' seconds')\n",
    "    \n",
    "    cells, cell_sets = first_candidates(cells, cell_sets, min_shared_cells)\n",
    "    \n",
    "    print(str(len(cells)) + ' genes made have > ' + str(min_shared_cells) + ' cells')\n",
    "    \n",
    "    k = 2\n",
    "    n = len(cells)\n",
    "    \n",
    "    pickle_cells(cell_sets, k)\n",
    "    \n",
    "    while(len(cells) > 0 and k < max_cluster_size):\n",
    "        st = time.time()\n",
    "        \n",
    "        q = mp.JoinableQueue()\n",
    "        \n",
    "        candidates_output = []\n",
    "        candidate_iter = iter(cell_sets.keys())\n",
    "        kwarg_dict={'k':k,'full_list':cell_sets.keys(),'q':q}\n",
    "        \n",
    "        for i in range(cores-1):\n",
    "            p = mp.Process(target=parallel_combo_generator, args=(it.islice(candidate_iter, n//cores),), kwargs=kwarg_dict)\n",
    "            p.start()\n",
    "\n",
    "        for i in range(1):\n",
    "            p = mp.Process(target=parallel_combo_generator, args=(it.islice(candidate_iter, n//cores),), kwargs=kwarg_dict)\n",
    "            p.start()\n",
    "            \n",
    "        for i in range(cores):\n",
    "            t = q.get()\n",
    "            candidates_output += [t] if t is not None else []\n",
    "            q.task_done()\n",
    "            \n",
    "        while(not q.empty()):\n",
    "            q.get()\n",
    "            q.task_done()\n",
    "            \n",
    "        q.join()\n",
    "        q.close()\n",
    "        \n",
    "        if(len(candidates_output) == 0):\n",
    "            print('No new candidates!')\n",
    "            print('Terminated! Total run time: ' + str(en - begin) + ' seconds')\n",
    "            break\n",
    "            \n",
    "        lengths, candidates_left, candidates_right = zip(*candidates_output)\n",
    "        candidates_left = it.chain.from_iterable(candidates_left)\n",
    "        candidates_right = it.chain.from_iterable(candidates_right)\n",
    "        cand_len = sum(lengths) \n",
    "        \n",
    "        q = mp.JoinableQueue()\n",
    "        \n",
    "        kwarg_dict={'min_shared_cells':min_shared_cells,'cell_sets':cell_sets,'q':q}\n",
    "\n",
    "        for i in range(cores-1):\n",
    "            p = mp.Process(target=make_gener, args=(list(it.islice(candidates_left, cand_len//cores)), list(it.islice(candidates_right, cand_len//cores))), kwargs=kwarg_dict)\n",
    "            p.start()\n",
    "\n",
    "        for i in range(1):\n",
    "            p = mp.Process(target=make_gener, args=(list(candidates_left), list(candidates_right)), kwargs=kwarg_dict)\n",
    "            p.start()\n",
    "\n",
    "        en = time.time()\n",
    "        print('Finished launching processes in: '+ str(time.time()-st) + ' seconds')\n",
    "            \n",
    "        output = []\n",
    "        for i in range(cores):\n",
    "            t = q.get()\n",
    "            output += [t] if t is not None else []\n",
    "            q.task_done()\n",
    "            \n",
    "        print('Finished merging cells in: ' + str(time.time() - en) + ' seconds')\n",
    "            \n",
    "        if(len(output) == 0):\n",
    "            print('No results from parallel output!')\n",
    "            print('Terminated! Total run time: ' + str(en - begin) + ' seconds')\n",
    "            break\n",
    "            \n",
    "\n",
    "        cell_sets = ft.reduce(lambda x,y: {**x, **y}, output)\n",
    "        \n",
    "        k+= 1\n",
    "        n = len(cell_sets)\n",
    "        \n",
    "        en = time.time()\n",
    "        \n",
    "        print('Found ' + str(n) + ' remaining gene clusters with > ' + str(min_shared_cells) + ' of size: ' +str(k-1))\n",
    "        print('Iteration took: ' + str(en-st) + ' seconds')\n",
    "        print('Running time: ' + str(en - begin) + ' seconds')\n",
    "        \n",
    "        if(n == 0):\n",
    "            print('Terminated! Total run time: ' + str(en - begin) + ' seconds')\n",
    "            break\n",
    "        else:\n",
    "            print('Pickling!')\n",
    "            pickle_cells(cell_sets, k-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fast_gather_gene_sets(dat, min_percent_cells = 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
